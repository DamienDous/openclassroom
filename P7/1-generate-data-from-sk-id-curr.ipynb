{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b403e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:25:09.303435Z",
     "start_time": "2022-07-20T13:25:09.259040Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from contextlib import contextmanager\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import csv\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "class DataGeneration:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def __get_columns(self, reader):\n",
    "        for row in reader:\n",
    "            columns = row\n",
    "            break\n",
    "        return columns\n",
    "\n",
    "    def __get_data_from_idx(self, csv_path, idx, col_id, idx_list):\n",
    "        column_types_df = pd.read_csv(csv_path+'.csv', nrows=1)\n",
    "        file = open(csv_path+idx+'.csv')\n",
    "        reader = csv.reader(file)\n",
    "        selected_data = pd.DataFrame(columns=self.__get_columns(reader))\n",
    "        selected_data = selected_data.astype(dtype=column_types_df.dtypes)\n",
    "        for row in reader:\n",
    "            if row[col_id] in idx_list:\n",
    "                line = []\n",
    "                for item in row:\n",
    "                    if item == '':\n",
    "                        line.append(float(np.nan))\n",
    "                    else:\n",
    "                        try:\n",
    "                            line.append(int(item))\n",
    "                        except:\n",
    "                            try:\n",
    "                                line.append(float(item))\n",
    "                            except:\n",
    "                                line.append(str(item))\n",
    "                selected_data.loc[len(selected_data)] = line\n",
    "        return selected_data\n",
    "\n",
    "    def __one_hot_encoder(self, df, nan_as_category=True):  # One-hot encoding for categorical columns with get_dummies\n",
    "        original_columns = list(df.columns)\n",
    "        categorical_columns = [\n",
    "            col for col in df.columns if df[col].dtype == 'object']\n",
    "        df = pd.get_dummies(df, columns=categorical_columns,\n",
    "                            dummy_na=nan_as_category)\n",
    "        new_columns = [c for c in df.columns if c not in original_columns]\n",
    "        return df, new_columns\n",
    "\n",
    "    def __application_train(self, df, nan_as_category=False):\n",
    "        # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "        df = df[df['CODE_GENDER'] != 'XNA']\n",
    "        # Categorical features with Binary encode (0 or 1; two categories)\n",
    "        for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "            df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "        # Categorical features with One-Hot encode\n",
    "        df, cat_cols = self.__one_hot_encoder(df, nan_as_category)\n",
    "        # Transform hot encoded categorical columns type as 'category' type\n",
    "        df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "        # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "        if 365243 in df['DAYS_EMPLOYED']:\n",
    "            df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "        # Some simple new features (percentages)\n",
    "        df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "        df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "        df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "        df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "        df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "        gc.collect()\n",
    "        return df\n",
    "\n",
    "    def __bureau_and_balance(self, bureau, bb, nan_as_category=True):\n",
    "        bureau, bureau_cat = self.__one_hot_encoder(bureau, nan_as_category)\n",
    "        bb, bb_cat = self.__one_hot_encoder(bb, nan_as_category)\n",
    "        # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "        bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "        for col in bb_cat:\n",
    "            bb_aggregations[col] = ['mean']\n",
    "        bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "        bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper()\n",
    "                                  for e in bb_agg.columns.tolist()])\n",
    "        bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "        bureau.drop(['SK_ID_BUREAU'], axis=1, inplace=True)\n",
    "        del bb, bb_agg\n",
    "        gc.collect()\n",
    "\n",
    "        # Bureau and bureau_balance numeric features\n",
    "        num_aggregations = {\n",
    "            'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "            'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "            'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "            'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "            'AMT_ANNUITY': ['max', 'mean'],\n",
    "            'CNT_CREDIT_PROLONG': ['sum'],\n",
    "            'MONTHS_BALANCE_MIN': ['min'],\n",
    "            'MONTHS_BALANCE_MAX': ['max'],\n",
    "            'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "        }\n",
    "        # Bureau and bureau_balance categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in bureau_cat:\n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        for cat in bb_cat:\n",
    "            cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "        bureau_agg = bureau.groupby('SK_ID_CURR').agg(\n",
    "            {**num_aggregations, **cat_aggregations})\n",
    "        bureau_agg.columns = pd.Index(\n",
    "            ['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "        # Bureau: Active credits - using only numerical aggregations\n",
    "        if 'CREDIT_ACTIVE_Active' in bureau.columns:\n",
    "            active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "            active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "            active_agg.columns = pd.Index(\n",
    "                ['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "            bureau_agg = bureau_agg.join(\n",
    "                active_agg, how='left', on='SK_ID_CURR')\n",
    "            del active, active_agg\n",
    "            gc.collect()\n",
    "        # Bureau: Closed credits - using only numerical aggregations\n",
    "        if 'CREDIT_ACTIVE_Closed' in bureau.columns:\n",
    "            closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "            closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "            closed_agg.columns = pd.Index(\n",
    "                ['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "            bureau_agg = bureau_agg.join(\n",
    "                closed_agg, how='left', on='SK_ID_CURR')\n",
    "            del closed, closed_agg\n",
    "            gc.collect()\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "        return bureau_agg\n",
    "\n",
    "    def __previous_applications(self, prev, nan_as_category=True):\n",
    "        prev, cat_cols = self.__one_hot_encoder(prev, nan_as_category)\n",
    "        # Days 365.243 values -> nan\n",
    "        prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "        prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "        prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "        prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "        prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "        # Add feature: value ask / value received percentage\n",
    "        prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "        # Previous applications numeric features\n",
    "        num_aggregations = {\n",
    "            'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "            'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "            'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "            'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "            'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "            'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "            'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "            'CNT_PAYMENT': ['mean', 'sum'],\n",
    "        }\n",
    "        # Previous applications categorical features\n",
    "        cat_aggregations = {}\n",
    "        for cat in cat_cols:\n",
    "            cat_aggregations[cat] = ['mean']\n",
    "        prev_agg = prev.groupby('SK_ID_CURR').agg(\n",
    "            {**num_aggregations, **cat_aggregations})\n",
    "        prev_agg.columns = pd.Index(\n",
    "            ['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "        # Previous Applications: Approved Applications - only numerical features\n",
    "        if 'NAME_CONTRACT_STATUS_Approved' in prev.columns:\n",
    "            approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "            approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "            approved_agg.columns = pd.Index(\n",
    "                ['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "            prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "            del approved, approved_agg\n",
    "        # Previous Applications: Refused Applications - only numerical features\n",
    "        if 'NAME_CONTRACT_STATUS_Refused' in prev.columns:\n",
    "            refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "            refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "            refused_agg.columns = pd.Index(\n",
    "                ['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "            prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "            del refused, refused_agg\n",
    "        del prev\n",
    "        gc.collect()\n",
    "        return prev_agg\n",
    "\n",
    "    def __pos_cash(self, pos, num_rows=None, nan_as_category=True):\n",
    "        pos, cat_cols = self.__one_hot_encoder(pos, nan_as_category)\n",
    "        # Features\n",
    "        aggregations = {\n",
    "            'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "            'SK_DPD': ['max', 'mean'],\n",
    "            'SK_DPD_DEF': ['max', 'mean']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "\n",
    "        pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        pos_agg.columns = pd.Index(\n",
    "            ['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "        # Count pos cash accounts\n",
    "        pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "        del pos\n",
    "        gc.collect()\n",
    "        return pos_agg\n",
    "\n",
    "    def __installments_payments(self, ins, num_rows=None, nan_as_category=True):\n",
    "        ins, cat_cols = self.__one_hot_encoder(ins, nan_as_category)\n",
    "        # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "        ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "        ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "        # Days past due and days before due (no negative values)\n",
    "        ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "        ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "        ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "        ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "        # Features: Perform aggregations\n",
    "        aggregations = {\n",
    "            'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "            'DPD': ['max', 'mean', 'sum'],\n",
    "            'DBD': ['max', 'mean', 'sum'],\n",
    "            'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "            'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "            'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "            'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "            'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "        }\n",
    "        for cat in cat_cols:\n",
    "            aggregations[cat] = ['mean']\n",
    "        ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "        ins_agg.columns = pd.Index(\n",
    "            ['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "        # Count installments accounts\n",
    "        ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "        del ins\n",
    "        gc.collect()\n",
    "        return ins_agg\n",
    "\n",
    "    def __credit_card_balance(self, cc, nan_as_category=True):\n",
    "        cc, cat_cols = self.__one_hot_encoder(cc, nan_as_category)\n",
    "        # General aggregations\n",
    "        cc.drop(['SK_ID_PREV'], axis=1, inplace=True)\n",
    "        cc_agg = cc.groupby('SK_ID_CURR').agg(\n",
    "            ['min', 'max', 'mean', 'sum', 'var'])\n",
    "        cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper()\n",
    "                                  for e in cc_agg.columns.tolist()])\n",
    "        # Count credit card lines\n",
    "        cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "        del cc\n",
    "        gc.collect()\n",
    "        return cc_agg\n",
    "\n",
    "    def process_database(self, dataframes):\n",
    "        df = self.__application_train(dataframes['application_train'])\n",
    "        bureau = self.__bureau_and_balance(dataframes['bureau'], dataframes['bureau_balance'])\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        prev = self.__previous_applications(\n",
    "            dataframes['previous_application'])\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        pos = self.__pos_cash(dataframes['POS_CASH_balance'])\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        ins = self.__installments_payments(dataframes['installments_payments'])\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        cc = self.__credit_card_balance(dataframes['credit_card_balance'])\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "\n",
    "        # Replace infinity values by nan\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df = df.rename(columns=lambda x: re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        return df\n",
    "\n",
    "    def write_idx_data(self, files_dict, curr_id):\n",
    "        for key, value in files_dict.items():\n",
    "            df = self.__get_data_from_idx(\n",
    "                'data/'+value[0], '', value[1], [curr_id])\n",
    "            df.to_csv('data/'+value[0]+curr_id+'.csv',\n",
    "                      index_label='SK_ID_CURR', index=False)\n",
    "\n",
    "            if value[0] == 'bureau':\n",
    "                bb = self.__get_data_from_idx(\n",
    "                    'data/bureau_balance', '', 0, list(df['SK_ID_BUREAU']))\n",
    "                bb.to_csv('data/bureau_balance'+curr_id+'.csv',\n",
    "                          index_label='SK_ID_BUREAU', index=False)\n",
    "        return\n",
    "\n",
    "    def get_idx_data(self, files_dict, curr_id):\n",
    "        dataframes = {}\n",
    "        for key, value in files_dict.items():\n",
    "            dataframes[value[0]] = self.__get_data_from_idx(\n",
    "                'data/'+value[0], curr_id, value[1], [curr_id])\n",
    "            \n",
    "            if value[0] == 'bureau':\n",
    "                dataframes['bureau_balance'] = self.__get_data_from_idx(\n",
    "                    'data/bureau_balance', '', 0, list(dataframes[value[0]]['SK_ID_BUREAU']))\n",
    "                \n",
    "        return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf3569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:27:39.035513Z",
     "start_time": "2022-07-20T13:26:20.700824Z"
    }
   },
   "outputs": [],
   "source": [
    "obj = DataGeneration()\n",
    "\n",
    "files_dict = {\n",
    "    1: ('application_train', 0),\n",
    "    2: ('bureau', 0),\n",
    "    3: ('previous_application', 1),\n",
    "    4: ('POS_CASH_balance', 1),\n",
    "    5: ('installments_payments', 1),\n",
    "    6: ('credit_card_balance', 1)\n",
    "}\n",
    "\n",
    "idx_curr = '100003'\n",
    "obj.write_idx_data(files_dict, idx_curr)\n",
    "dataframes = obj.get_idx_data(files_dict, idx_curr)\n",
    "df = obj.process_database(dataframes)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10ebe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e89cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8877ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:40:07.182623Z",
     "start_time": "2022-07-23T11:39:20.887710Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "file_list = [\n",
    "    'data/application_train.csv',\n",
    "    'data/credit_card_balance.csv',\n",
    "    'data/bureau_balance.csv',\n",
    "    'data/POS_CASH_balance.csv',\n",
    "    'data/bureau.csv',\n",
    "    'data/installments_payments.csv',\n",
    "    'data/previous_application.csv'\n",
    "]\n",
    "\n",
    "unique_items_df = pd.DataFrame()\n",
    "for file in file_list:\n",
    "    dataframe = pd.read_csv(file)\n",
    "    df_obj = dataframe.select_dtypes(include='object')\n",
    "    for column in df_obj.columns:\n",
    "        if column not in unique_items_df.columns:\n",
    "            unique_items_df = pd.concat([unique_items_df, pd.DataFrame(\n",
    "                df_obj[column][df_obj[column].notnull()].unique(), columns=[column])], axis=1)\n",
    "        else:\n",
    "            list1 = list(unique_items_df[column])\n",
    "            list2 = list(df_obj[column].unique())\n",
    "            list1.extend(list2)\n",
    "            new_set = set(list1)\n",
    "            unique_items_df.drop(column, inplace=True, axis=1)\n",
    "            unique_items_df = pd.concat([unique_items_df, pd.DataFrame(\n",
    "                df_obj[column].unique(), columns=[column])], axis=1) \n",
    "            \n",
    "unique_items_df.loc[-1] = 'undefined'\n",
    "unique_items_df.index = unique_items_df.index + 1  # shifting index\n",
    "unique_items_df.sort_index(inplace=True)\n",
    "\n",
    "unique_items_df.to_csv(\"data/unique_items_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa0680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:40:07.864054Z",
     "start_time": "2022-07-23T11:40:07.855712Z"
    }
   },
   "outputs": [],
   "source": [
    "print(unique_items_df.columns)\n",
    "unique_items_df.loc[-1] = 'undefined'\n",
    "unique_items_df.index = unique_items_df.index + 1  # shifting index\n",
    "unique_items_df.sort_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f2b950",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:40:08.379901Z",
     "start_time": "2022-07-23T11:40:08.374413Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_items_df.to_csv(\"data/unique_items_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069093d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa5b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T18:12:11.129840Z",
     "start_time": "2022-07-20T18:12:11.112092Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21569a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142d322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09820a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T12:39:57.833367Z",
     "start_time": "2022-07-22T12:39:56.843525Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('data/application_train.csv', usecols=['SK_ID_CURR']).T.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289358b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T12:40:02.579751Z",
     "start_time": "2022-07-22T12:40:02.556400Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d9fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "266px",
    "left": "1310px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
