{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d90639",
   "metadata": {},
   "source": [
    "# Import the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8384d",
   "metadata": {},
   "source": [
    "## Read the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69b986",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T07:51:37.155974Z",
     "start_time": "2022-07-12T07:51:32.684878Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Main table\n",
    "pd.options.display.max_columns = None\n",
    "train = pd.read_pickle('data/global_train_data.pkl').sample(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dd902",
   "metadata": {},
   "source": [
    "## Split the training and validation sets\n",
    "For some early model runs, we used as little as 10% of the training data. By the end, we were using 75% for training and holding back 25% for validation. The parameter that controls the proportion of the train/test split is called test_size and can be found in the first code cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a4554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T07:51:41.752823Z",
     "start_time": "2022-07-12T07:51:40.658423Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = train['TARGET'].values\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop(\n",
    "    ['TARGET', 'SK_ID_CURR'], axis=1), y, stratify=y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71f380",
   "metadata": {},
   "source": [
    "## build model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc43c73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T07:51:56.990615Z",
     "start_time": "2022-07-12T07:51:46.310923Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# preprocessing steps\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        # tried median, mean, constant strategies\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_train = pipe.transform(X_train)\n",
    "X_valid = pipe.transform(X_valid)\n",
    "\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_valid:', X_valid.shape)\n",
    "print('Shape of y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c018c",
   "metadata": {},
   "source": [
    "# Balancing data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92356e8f",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06b711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T09:09:19.830767Z",
     "start_time": "2022-07-12T09:09:19.669026Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def get_statistics(_y_valid, _y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(\n",
    "        list(_y_valid), list(_y_pred), labels=[0, 1]).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    specifity = TN/(TN+FP)\n",
    "    # Precision or positive predictive value\n",
    "    precision = TP/(TP+FP)\n",
    "    # Overall accuracy\n",
    "    accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    return TN, FP, FN, TP, sensitivity, specifity, precision, accuracy\n",
    "\n",
    "\n",
    "def eval_error(_y_valid, _y_pred):\n",
    "    TN, FP, FN, TP = confusion_matrix(\n",
    "        list(_y_valid), list(_y_pred), labels=[0, 1]).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    sensitivity = TP/(TP+FN)\n",
    "    # Overall accuracy\n",
    "    accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "    value = sensitivity*accuracy\n",
    "    return \"error\", value, True\n",
    "\n",
    "\n",
    "def process_fitting(_name, _pipeline):\n",
    "    _pipeline.fit(X_train, y_train, \n",
    "                      lgbmclassifier__eval_metric=eval_error)\n",
    "    TN, FP, FN, TP, sensitivity, specifity, precision, accuracy = get_statistics(\n",
    "        y_valid, _pipeline.predict(X_valid))\n",
    "    result = pd.DataFrame({'Preprocess': [_name],\n",
    "                           'TN': [TN],\n",
    "                           'FP': [FP],\n",
    "                           'FN': [FN],\n",
    "                           'TP': [TP],\n",
    "                           'sensitivity': [sensitivity],\n",
    "                           'accuracy': [accuracy],\n",
    "                           'score': [eval_error(y_valid, _pipeline.predict(X_valid))[1]]})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18095d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T09:09:23.317528Z",
     "start_time": "2022-07-12T09:09:23.172336Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classifier = lgb.LGBMClassifier(boosting_type='gbdt', objective='binary', max_depth=18,\n",
    "                              # default learning rate is 0.1 but 0.02 feels like the sweet spot.\n",
    "                              n_jobs=-1, num_leaves=30, learning_rate=0.02, n_estimators=1600,\n",
    "                              max_bin=512, subsample_for_bin=200, subsample=0.8,\n",
    "                              subsample_freq=1, colsample_bytree=0.8,\n",
    "                              # bumping up the alpha parameter gave us a little boost\n",
    "                              reg_alpha=80, reg_lambda=20,\n",
    "                              min_split_gain=0.5, min_child_weight=1,\n",
    "                              # about 92% target=0 to 8% target=1 - ratio is about 11.5 to 1\n",
    "                              min_child_samples=10, scale_pos_weight=11.5, num_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e92530",
   "metadata": {},
   "source": [
    "## Fit models without balancing data - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf480abf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T09:09:25.989664Z",
     "start_time": "2022-07-12T09:09:25.855851Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Preprocess',\n",
    "                       'TN', 'FP', 'FN', 'TP', 'sensitivity', 'accuracy', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb2341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T09:16:12.761976Z",
     "start_time": "2022-07-12T09:09:28.532114Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# Create pipeline to predict classification from data\n",
    "pipeline = make_pipeline(\n",
    "    classifier\n",
    ")\n",
    "# Fit the pipeline\n",
    "result = process_fitting('None', pipeline)\n",
    "\n",
    "# update model scoreboard\n",
    "results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cef464",
   "metadata": {},
   "source": [
    "## Optimize SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbfc3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T09:33:38.926020Z",
     "start_time": "2022-07-11T09:33:38.925977Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sampling_strategy_values = [0.2, 0.5]\n",
    "k_values = [1, 5]\n",
    "\n",
    "for s in sampling_strategy_values:\n",
    "    for k in k_values:\n",
    "        print('sampling_strategy_values:', s, 'k_values:', k)\n",
    "        # Create pipeline to predict classification from data\n",
    "        pipeline = make_pipeline(\n",
    "            SMOTE(sampling_strategy=s, k_neighbors=k),\n",
    "            classifier\n",
    "        )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        result = process_fitting_metric('SMOTE - knn:'+str(k)+'- sampling:'+str(s), pipeline)\n",
    "\n",
    "        # update model scoreboard\n",
    "        results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96244ec",
   "metadata": {},
   "source": [
    "## Optimize BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da222ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T09:33:38.936140Z",
     "start_time": "2022-07-11T09:33:38.936100Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "sampling_strategy_values = [0.2, 0.5]\n",
    "k_values = [1, 5]\n",
    "\n",
    "for s in sampling_strategy_values:\n",
    "    for k in k_values:\n",
    "        print('sampling_strategy_values:', s, 'k_values:', k)\n",
    "        # Create pipeline to predict classification from data\n",
    "        pipeline = make_pipeline(\n",
    "            BorderlineSMOTE(k_neighbors=k, sampling_strategy=s),\n",
    "            classifier\n",
    "        )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        result = process_fitting_metric('BorderlineSMOTE - knn:'+str(k)+'- sampling:'+str(s), pipeline)\n",
    "\n",
    "        # update model scoreboard\n",
    "        results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0041a2a5",
   "metadata": {},
   "source": [
    "## Optimize ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a7f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T09:33:38.947347Z",
     "start_time": "2022-07-11T09:33:38.947312Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "sampling_strategy_values = [0.2, 0.5]\n",
    "k_values = [1, 5]\n",
    "\n",
    "for s in sampling_strategy_values:\n",
    "    for k in k_values:\n",
    "        print('sampling_strategy_values:', s, 'k_values:', k)\n",
    "        # Create pipeline to predict classification from data\n",
    "        pipeline = make_pipeline(\n",
    "            ADASYN(n_neighbors=k, sampling_strategy=s),\n",
    "            classifier\n",
    "        )\n",
    "\n",
    "        # Fit the pipeline\n",
    "        result = process_fitting_metric('ADASYN - knn:'+str(k)+'- sampling:'+str(s), pipeline)\n",
    "\n",
    "        # update model scoreboard\n",
    "        results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4db63",
   "metadata": {},
   "source": [
    "## Optimize SMOTE with RandomUndersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ae74f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-11T09:33:38.957024Z",
     "start_time": "2022-07-11T09:33:38.956973Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampling_strategy_values = [0.2, 0.3, 0.5, 1]\n",
    "\n",
    "for s in sampling_strategy_values:\n",
    "    print('sampling_strategy_values:', s)\n",
    "    # Create pipeline to predict classification from data\n",
    "    pipeline = make_pipeline(\n",
    "        SMOTE(sampling_strategy=0.5, k_neighbors=1),\n",
    "        RandomUnderSampler(sampling_strategy=s),\n",
    "        classifier\n",
    "    )\n",
    "\n",
    "    # Fit the pipeline\n",
    "    result = process_fitting_metric('SMOTE UNDER - undersampling:'+str(s), pipeline)\n",
    "\n",
    "    # update model scoreboard\n",
    "    results = pd.concat([results, result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c67f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T07:54:51.054909Z",
     "start_time": "2022-07-12T07:54:51.034978Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be5ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
